{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "import aizynthfinder.analysis\n",
    "import aizynthfinder.chem\n",
    "import aizynthfinder.context.config as con\n",
    "\n",
    "from aizynthfinder.mcts.node import Node\n",
    "from aizynthfinder.analysis import ReactionTree\n",
    "from aizynthfinder.mcts.state import State\n",
    "from aizynthfinder.chem import TreeMolecule\n",
    "from aizynthfinder.context.collection import ContextCollection\n",
    "from aizynthfinder.context.stock import StockException\n",
    "import aizynthfinder.context.scoring as scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_output = '/data/localhost/not-backed-up/mokaya/exscientia/aizynthfinder/Maranga/similarity/results/t2_aug0_single_explr.txt'\n",
    "args_input = '/data/localhost/not-backed-up/mokaya/exscientia/aizynthfinder/Maranga/similarity/results/target_2_single_explr.json'\n",
    "args_config = '/data/localhost/not-backed-up/mokaya/exscientia/aizynthfinder/aizynthfinder/data/config.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args_input) as inf:\n",
    "    jsonfile = json.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "RUN:  0\n",
      "RUN:  1\n",
      "RUN:  2\n",
      "RUN:  3\n",
      "\n",
      "\n",
      "Rank, Reaction, Frequency, Policy value\n",
      "0,Amide to amine reduction, 8, 0.0010000000474974513\n",
      "1,Other functional group interconversion, 8, 0.00019999999494757503\n",
      "2,Heteroaryl N-alkylation, 4, 0.0008999999845400453\n",
      "Rank, Reaction, Frequency, Policy, Literature\n",
      "1,Amide to amine reduction, 8, 0.001, 29.0\n",
      "2,Other functional group interconversion, 8, 0.0002, 146.0\n",
      "3,Heteroaryl N-alkylation, 4, 0.0009, 39.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-90e39dfc108f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m \u001b[0mrxns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mReactionTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjsonfile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-90e39dfc108f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m \u001b[0mrxns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mReactionTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjsonfile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/pegasus/not-backed-up/mokaya/exscientia/aizynthfinder/aizynthfinder/analysis.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, tree_dict)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaction\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \"\"\"\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mReactionTreeFromDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUniqueMolecule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFixedRetroReaction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/pegasus/not-backed-up/mokaya/exscientia/aizynthfinder/aizynthfinder/utils/analysis_helpers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReactionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         self.tree.is_solved = all(\n",
      "\u001b[0;32m/data/pegasus/not-backed-up/mokaya/exscientia/aizynthfinder/aizynthfinder/utils/analysis_helpers.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, tree_dict)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStrDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_tree_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_parse_tree_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStrDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUniqueMolecule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/pegasus/not-backed-up/mokaya/exscientia/aizynthfinder/aizynthfinder/utils/analysis_helpers.py\u001b[0m in \u001b[0;36m_parse_tree_dict\u001b[0;34m(self, tree_dict, ncalls)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_parse_tree_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStrDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUniqueMolecule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mproduct_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUniqueMolecule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"smiles\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         self._add_node(\n\u001b[1;32m     81\u001b[0m             \u001b[0mproduct_node\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "'''\n",
    "f = open(args_output, 'a')\n",
    "f.write('Results file for: '+args_input)\n",
    "\n",
    "#import data from .hdf5 file\n",
    "#data = pd.read_hdf(args_input, 'table')\n",
    "\n",
    "solved_data = data.loc[(data.is_solved==True)]\n",
    "unsolved_data = data.loc[(data.is_solved==False)]\n",
    "all_solved = data.is_solved.values\n",
    "\n",
    "true = []\n",
    "false = []\n",
    "\n",
    "for i in range(len(all_solved)):\n",
    "    if all_solved[i] == True:\n",
    "        true.append(i)\n",
    "    else:\n",
    "        false.append(i)\n",
    "\n",
    "print('True:', (len(true)/len(all_solved))*100)\n",
    "print('False: ', (len(false)/len(all_solved))*100)\n",
    "\n",
    "f.write('True: '+str((len(true)/len(all_solved))*100))\n",
    "f.write('False: '+str((len(false)/len(all_solved))*100))\n",
    "\n",
    "all_trees = data.trees.values\n",
    "all_solved_trees = solved_data.trees.values\n",
    "all_unsolved_trees = unsolved_data.trees.values\n",
    "\n",
    "\n",
    "json_results = []\n",
    "solved_json_results = []\n",
    "print('length of solved trees: ', len(all_solved_trees))\n",
    "print('length of unsolved trees: ', len(all_unsolved_trees))\n",
    "unsolved_json_results = []\n",
    "\n",
    "for i in all_trees:\n",
    "    for itree, tree in enumerate(i):\n",
    "        reaction_json = ReactionTree.from_dict(tree).to_json()\n",
    "        json_results.append(reaction_json)\n",
    "\n",
    "for i in all_unsolved_trees:\n",
    "    for itree, tree in enumerate(i):\n",
    "        unsolved_reaction_json = ReactionTree.from_dict(tree).to_json()\n",
    "        unsolved_json_results.append(unsolved_reaction_json)\n",
    "\n",
    "for i in all_solved_trees:\n",
    "    for itree, tree in enumerate(i):\n",
    "        solved_reaction_json = ReactionTree.from_dict(tree).to_json()\n",
    "        solved_json_results.append(solved_reaction_json)\n",
    "\n",
    "\n",
    "solved_json_results = [json.loads(i) for i in solved_json_results]\n",
    "'''\n",
    "#solved reaction parse rxn tree\n",
    "solved_reaction_data = []\n",
    "\n",
    "print(len(jsonfile))\n",
    "\n",
    "for p in range(len(jsonfile)-1):\n",
    "    print('RUN: ', p)\n",
    "    for i in jsonfile:\n",
    "        if 'children' in i:\n",
    "            child = i.get('children')[0]\n",
    "            if child.get('type') == 'reaction':\n",
    "                metadata = child.get('metadata')\n",
    "                solved_reaction_data.append((child.get('smiles'), metadata.get('classification'), metadata.get('library_occurence'), metadata.get('policy_probability')))\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            del jsonfile[-1]\n",
    "\n",
    "smiles = [i[0] for i in solved_reaction_data]\n",
    "classification = [i[1] for i in solved_reaction_data]\n",
    "uspto_freq = [i[2] for i in solved_reaction_data]\n",
    "policy = [i[3] for i in solved_reaction_data]\n",
    "\n",
    "\n",
    "reaction_class = {}\n",
    "\n",
    "for i in classification:\n",
    "    if (i in reaction_class):\n",
    "        reaction_class[i]['Frequency'] += 1\n",
    "    else:\n",
    "        reaction_class[i] = {}\n",
    "        reaction_class[i]['Frequency'] = 1\n",
    "\n",
    "reaction_class = dict(sorted(reaction_class.items(), key=lambda item: item[1]['Frequency'], reverse=True))\n",
    "\n",
    "#calculate average policy predictions for each grouped reaction\n",
    "\n",
    "reaction_class_policy = {}\n",
    "reaction_class_freq = {}\n",
    "\n",
    "for i in solved_reaction_data: \n",
    "    if i[1] in reaction_class_policy:\n",
    "        reaction_class_policy[i[1]] += i[3]\n",
    "        reaction_class_freq[i[1]] += 1\n",
    "    else:\n",
    "        reaction_class_policy[i[1]] = i[3]\n",
    "        reaction_class_freq[i[1]] = 1\n",
    "\n",
    "reaction_class_policy_mean = {}\n",
    "\n",
    "for i in reaction_class_policy:\n",
    "    reaction_class_policy_mean[i] = (reaction_class_policy.get(i)/reaction_class_freq.get(i))\n",
    "\n",
    "#reaction_class_policy_mean = dict(sorted(reaction_class_policy_mean.items(), key=lambda item: item[1], reverse=True))\n",
    "print('\\n')\n",
    "print('Rank, Reaction, Frequency, Policy value')\n",
    "\n",
    "'''for x in reaction_class_policy_mean:\n",
    "    print (x + '    '+ str(reaction_class_policy_mean[x]))'''\n",
    "\n",
    "for i in reaction_class:\n",
    "    reaction_class[i]['Policy'] = reaction_class_policy_mean.get(i)\n",
    "\n",
    "count = 0\n",
    "for i in reaction_class:\n",
    "    print(str(count)+','+i+', '+str(reaction_class[i]['Frequency'])+', '+str(reaction_class[i]['Policy']))\n",
    "    count+=1\n",
    "\n",
    "reaction_class_lit = {}\n",
    "reaction_class_freq = {}\n",
    "\n",
    "for i in solved_reaction_data: \n",
    "    if i[1] in reaction_class_lit:\n",
    "        reaction_class_lit[i[1]] += i[2]\n",
    "        reaction_class_freq[i[1]] += 1\n",
    "    else:\n",
    "        reaction_class_lit[i[1]] = i[2]\n",
    "        reaction_class_freq[i[1]] = 1\n",
    "\n",
    "reaction_class_lit_mean = {}\n",
    "\n",
    "\n",
    "for i in reaction_class_lit:\n",
    "    reaction_class_lit_mean[i] = (reaction_class_lit.get(i)/reaction_class_freq.get(i))\n",
    "\n",
    "reaction_class_lit_mean = dict(sorted(reaction_class_lit_mean.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "print('Rank, Reaction, Frequency, Policy, Literature')\n",
    "#f.write('\\n\\nRank, Reaction, Frequency, Policy, Literature\\n')\n",
    "\n",
    "'''for x in reaction_class_lit_mean:\n",
    "    print (x + '    '+ str(reaction_class_lit_mean[x]))'''\n",
    "\n",
    "\n",
    "for i in reaction_class:\n",
    "    reaction_class[i]['Literature'] = reaction_class_lit_mean.get(i)\n",
    "\n",
    "count = 1\n",
    "for i in reaction_class:\n",
    "    print(str(count)+','+i+', '+str(reaction_class[i]['Frequency'])+', '+str(round(reaction_class[i]['Policy'], 4))+', '+str(round(reaction_class[i]['Literature'], 0)))\n",
    "    #f.write(str(count)+','+i+', '+str(reaction_class[i]['Frequency'])+', '+str(round(reaction_class[i]['Policy'], 4))+', '+str(round(reaction_class[i]['Literature'], 0))+'\\n')\n",
    "    count+=1\n",
    "\n",
    "\n",
    "# route cost calculator\n",
    "config = con.Configuration()\n",
    "config = config.from_file(args_config)\n",
    "\n",
    "rxns = [ReactionTree.from_dict(tree) for i in jsonfile for x, tree in enumerate(i)]\n",
    "\n",
    "\n",
    "policy_scorer = scoring.USPTOModelPolicyProbabilityScorer()\n",
    "policy_scores = policy_scorer(rxns)\n",
    "policy_mean = np.mean(policy_scores)\n",
    "\n",
    "cost_scorer = scoring.RouteCostScorer(config=config)\n",
    "cost_scores = cost_scorer(rxns)\n",
    "cost_mean = np.mean(cost_scores)\n",
    "\n",
    "num_reactions_scorer = scoring.NumberOfReactionsScorer()\n",
    "num_reactions_scores = num_reactions_scorer(rxns)\n",
    "num_reactions_mean = np.mean(num_reactions_scores)\n",
    "\n",
    "overall_cost = (0.2*100 - (1/10)*100)/num_reactions_mean\n",
    "\n",
    "print('policy: ', policy_mean)\n",
    "#f.write('\\n\\npolicy: '+ str(policy_mean)+'\\n')\n",
    "\n",
    "print('Cost: ', cost_mean)\n",
    "#f.write('Cost: '+ str(cost_mean)+'\\n')\n",
    "\n",
    "print('Cost Term: ', cost_mean/100)\n",
    "\n",
    "print('Num reactions: ', num_reactions_mean)\n",
    "#f.write('Num Reactions: '+ str(num_reactions_mean)+'\\n')\n",
    "\n",
    "print('Target Library Synthesis Cost: ', cost_mean)\n",
    "#f.write('Target Lib cost: '+ str(cost_mean)+'\\n')\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_reactions(nested_dict, in_list):\n",
    "    all_reactions = []\n",
    "    for key, value in nested_dict.items():\n",
    "        #print('Key: ', key)\n",
    "        #print('Value', value)\n",
    "        if value == 'mol':\n",
    "            #print('mol found')\n",
    "            children  = nested_dict.get('children')\n",
    "            for i in children:\n",
    "                if 'children' in i:\n",
    "                    get_all_reactions(nested_dict=i, in)\n",
    "        elif value == 'reaction':\n",
    "            #print('reaction found')\n",
    "            metadata = nested_dict.get('metadata')\n",
    "            #print(metadata)\n",
    "            all_reactions.append((metadata.get('classification'), metadata.get('library_occurence'), metadata.get('policy_probability')))\n",
    "            children  = nested_dict.get('children')\n",
    "            for i in children:\n",
    "                if 'children' in i:\n",
    "                    get_all_reactions(nested_dict=i)\n",
    "        elif (key == 'is_stock' and value=='True'):\n",
    "            #print('REACHED STOCK')\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "    return in_list+all_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in jsonfile:\n",
    "    results = get_all_reactions(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('aizynth-dev': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1ce81150a71727f589a159d7c025889054ace076bb44326ef3200601839cf7ad"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}